# Brendan Gregg Persona for Performance Analysis

## Overview

The **Brendan Gregg Persona** is an AI-powered performance analysis agent modeled after Brendan Gregg's methodologies and analytical style. It integrates with Prometheus metrics and Grafana dashboards to provide expert-level performance insights using proven methodologies from the "Systems Performance" book.

## Features

### üéØ Core Capabilities

1. **USE Method Analysis**
   - **Utilization**: How busy is each resource?
   - **Saturation**: Is there queued work?
   - **Errors**: Are there any errors?
   - Applied to: CPU, Memory, Disk, Network

2. **Prometheus Integration**
   - Execute PromQL queries
   - Collect instant and range metrics
   - Analyze time-series data
   - Support for custom queries

3. **Grafana Dashboard Analysis**
   - Fetch dashboard definitions
   - Extract panel queries
   - Analyze metrics in context
   - Correlate multiple panels

4. **Brendan's Analytical Style**
   - Data-driven insights with specific evidence
   - Structured investigation steps
   - Practical, actionable recommendations
   - Educational references to Systems Performance book

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Brendan Gregg Persona                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ PrometheusClient ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ USE Method       ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ        ‚îÇ Analyzer         ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - query_instant  ‚îÇ        ‚îÇ                  ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - query_range    ‚îÇ        ‚îÇ - CPU Analysis   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - get_metric     ‚îÇ        ‚îÇ - Memory         ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ - Disk           ‚îÇ         ‚îÇ
‚îÇ                               ‚îÇ - Network        ‚îÇ         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ  ‚îÇ GrafanaDashboard ‚îÇ                                      ‚îÇ
‚îÇ  ‚îÇ Analyzer         ‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Insight          ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - list_dashboard ‚îÇ        ‚îÇ Generator        ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - get_dashboard  ‚îÇ        ‚îÇ                  ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - extract_queries‚îÇ        ‚îÇ - Evidence       ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ - Root Cause     ‚îÇ         ‚îÇ
‚îÇ                               ‚îÇ - Recommendations‚îÇ         ‚îÇ
‚îÇ                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Installation

The persona is part of the system-performance project:

```bash
cd /Users/reinaldosaraiva/workspace/projects/python/system-performance

# Install dependencies
uv sync

# Activate virtual environment
source .venv/bin/activate
```

## Quick Start

### Basic Usage

```python
import asyncio
from src.brendan_gregg_persona import BrendanGreggPersona

async def analyze_system():
    # Initialize persona
    persona = BrendanGreggPersona(
        prometheus_url="http://localhost:9090",
        grafana_url="http://localhost:3000",
    )

    # Run USE Method analysis
    insights = await persona.analyze_use_method()

    # Generate report
    report = persona.generate_brendan_style_report(insights)
    print(report)

asyncio.run(analyze_system())
```

### Analyze Grafana Dashboard

```python
# List available dashboards
dashboards = persona.grafana.list_dashboards()
for dash in dashboards:
    print(f"{dash['title']} (UID: {dash['uid']})")

# Analyze specific dashboard
insights = await persona.analyze_grafana_dashboard("dashboard_uid")
```

### Query Prometheus Metrics

```python
# Get instant metric value
cpu_util = persona.prometheus.get_metric_value(
    '100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)'
)

# Execute custom query
result = persona.prometheus.query_instant("node_load1")
```

## Methodologies

### 1. USE Method

For every resource, check:

| Component | Utilization | Saturation | Errors |
|-----------|-------------|------------|--------|
| **CPU**   | % busy      | Load avg/CPU > 1 | CPU errors (rare) |
| **Memory**| % used      | Swap usage | OOM kills |
| **Disk**  | I/O time %  | Queue depth | I/O errors |
| **Network**| Bandwidth % | Drop rate  | Interface errors |

**When to use**: Initial system health check, comprehensive resource analysis

### 2. Workload Characterization

Understand the nature of the load:
- Who is causing the load?
- Why is the load being called?
- What is the load?
- How is the load changing over time?

**When to use**: Understanding application behavior, capacity planning

### 3. Drill-Down Analysis

Start from high-level metrics and progressively dig into details:
1. System-level metrics (CPU, Memory, Disk, Network)
2. Per-process metrics
3. Per-thread metrics
4. Function-level profiling

**When to use**: When USE Method identifies an issue, need detailed investigation

### 4. Latency Analysis

Focus on response time and delays:
- p50, p95, p99 latencies
- Latency distributions
- Outlier detection

**When to use**: User-facing performance problems, SLA violations

## Thresholds

Brendan's recommended thresholds (from Systems Performance book):

```python
THRESHOLDS = {
    "cpu": {
        "utilization_warning": 80.0,    # %
        "utilization_critical": 95.0,   # %
        "saturation_warning": 1.0,      # load per CPU
        "saturation_critical": 2.0,     # load per CPU
    },
    "memory": {
        "utilization_warning": 85.0,    # %
        "utilization_critical": 95.0,   # %
        "saturation_warning": 10.0,     # % swap usage
        "saturation_critical": 50.0,    # % swap usage
    },
    "disk": {
        "utilization_warning": 70.0,    # %
        "utilization_critical": 90.0,   # %
        "saturation_warning": 5.0,      # avg queue depth
        "saturation_critical": 10.0,    # avg queue depth
        "latency_warning": 10.0,        # ms
        "latency_critical": 50.0,       # ms
    },
    "network": {
        "utilization_warning": 70.0,    # % of bandwidth
        "utilization_critical": 90.0,   # % of bandwidth
        "error_rate_warning": 0.1,      # % packet errors
        "error_rate_critical": 1.0,     # % packet errors
    },
}
```

## Insight Structure

Each insight follows Brendan's analytical style:

```python
@dataclass
class BrendanGreggInsight:
    id: str
    timestamp: datetime
    methodology: AnalysisMethodology  # USE, TSA, Drill-Down, etc.
    component: str                     # cpu, memory, disk, network
    issue_type: PerformanceIssueType   # bottleneck, saturation, error, etc.
    severity: str                      # critical, high, medium, low, info
    title: str

    # Brendan's style: data-driven
    observation: str                   # What the data shows
    evidence: Dict[str, float]         # Specific metrics
    root_cause: str                    # Technical explanation

    # Brendan's style: practical
    immediate_action: str              # What to do now
    investigation_steps: List[str]     # How to dig deeper
    long_term_fix: str                 # Sustainable solution

    # Additional context
    related_metrics: List[str]
    confidence: float                  # 0-100
    book_reference: Optional[str]      # Reference to book chapter
```

## Examples

### Example 1: Full USE Method Analysis

```bash
# Run demo
uv run python examples/demo_brendan_gregg_persona.py

# Or use directly
uv run python src/brendan_gregg_persona.py
```

**Output:**
```
================================================================================
SYSTEMS PERFORMANCE ANALYSIS REPORT
Based on Brendan Gregg's Methodologies
================================================================================

Generated: 2025-10-28 14:30:00

SUMMARY:
  Critical Issues: 1
  High Priority:   2
  Medium Priority: 0
  Total Findings:  3

üö® CRITICAL ISSUES - IMMEDIATE ACTION REQUIRED
--------------------------------------------------------------------------------

[1] CPU Utilization at Critical Level
    Component: cpu
    Methodology: use_method

    OBSERVATION:
    CPU utilization is at 96.5%, exceeding the 95.0% critical threshold.

    EVIDENCE:
      ‚Ä¢ cpu_utilization: 96.5
      ‚Ä¢ cpu_count: 8
      ‚Ä¢ threshold_critical: 95.0

    ROOT CAUSE:
    High CPU utilization indicates the system is compute-bound. This could be
    due to inefficient algorithms, lack of caching, excessive context switching,
    or simply insufficient CPU resources for the workload.

    ‚ö° IMMEDIATE ACTION:
    Use `top` or `htop` to identify the top CPU consumers. Consider:
    1) Killing non-essential processes
    2) Moving workloads to other systems
    3) Reducing traffic/load if possible

    üîç INVESTIGATION STEPS:
      1. Run `mpstat -P ALL 1` to see per-CPU utilization
      2. Use `perf top` to identify hot functions
      3. Check `sar -u 1` for historical patterns
      4. Profile application with flame graphs
      5. Review application logs for unusual activity

    üîß LONG-TERM FIX:
    1) Optimize hot code paths identified in profiling
    2) Implement caching to reduce computation
    3) Scale horizontally by adding more CPU cores/instances
    4) Consider moving CPU-intensive tasks to background queues

    üìö Reference: Systems Performance 2nd Ed., Chapter 6: CPUs
```

### Example 2: Grafana Dashboard Analysis

```python
# Analyze USE Method dashboard
persona = BrendanGreggPersona()
insights = await persona.analyze_grafana_dashboard("use-method-dashboard-uid")

# Filter by severity
critical = [i for i in insights if i.severity == "critical"]
print(f"Found {len(critical)} critical issues")

# Get specific evidence
for insight in critical:
    print(f"\nIssue: {insight.title}")
    print("Evidence:")
    for key, value in insight.evidence.items():
        print(f"  - {key}: {value}")
```

### Example 3: Custom Prometheus Queries

```python
# Query specific metrics
cpu_queries = {
    "user_cpu": 'rate(node_cpu_seconds_total{mode="user"}[5m]) * 100',
    "system_cpu": 'rate(node_cpu_seconds_total{mode="system"}[5m]) * 100',
    "iowait": 'rate(node_cpu_seconds_total{mode="iowait"}[5m]) * 100',
}

for name, query in cpu_queries.items():
    value = persona.prometheus.get_metric_value(query)
    print(f"{name}: {value:.2f}%")
```

## Integration with AutoGen

The Brendan Gregg persona integrates seamlessly with the existing AutoGen multi-agent system:

```python
from autogen_integration import AutoGenIntegration, AgentRole, AnalysisFinding
from brendan_gregg_persona import BrendanGreggPersona

# Initialize both systems
autogen = AutoGenIntegration()
brendan = BrendanGreggPersona()

# Run Brendan's USE Method analysis
use_insights = await brendan.analyze_use_method()

# Convert to AutoGen findings
for insight in use_insights:
    finding = AnalysisFinding(
        id=insight.id,
        agent=AgentRole.PERFORMANCE_ANALYST,
        component=insight.component,
        severity=AnalysisSeverity[insight.severity.upper()],
        title=insight.title,
        description=insight.observation,
        recommendation=insight.immediate_action,
        metrics=insight.evidence,
        confidence=insight.confidence / 100,  # Convert to 0-1
        timestamp=insight.timestamp,
    )
    autogen.findings.append(finding)

# Continue with collaborative analysis
collaborative_analysis = await autogen.run_collaborative_analysis()
```

## Configuration

### Environment Variables

```bash
# Prometheus configuration
export PROMETHEUS_URL="http://localhost:9090"

# Grafana configuration
export GRAFANA_URL="http://localhost:3000"
export GRAFANA_USERNAME="admin"
export GRAFANA_PASSWORD="admin123"
# Or use API key (preferred)
export GRAFANA_API_KEY="your-api-key"

# Threshold overrides (optional)
export CPU_UTILIZATION_CRITICAL="95.0"
export MEMORY_UTILIZATION_CRITICAL="95.0"
```

### Customizing Thresholds

```python
# Override thresholds for your environment
persona = BrendanGreggPersona()

# Customize CPU thresholds
persona.THRESHOLDS["cpu"]["utilization_warning"] = 70.0
persona.THRESHOLDS["cpu"]["utilization_critical"] = 90.0

# Customize memory thresholds
persona.THRESHOLDS["memory"]["saturation_critical"] = 30.0

# Run analysis with custom thresholds
insights = await persona.analyze_use_method()
```

## Troubleshooting

### Prometheus Connection Issues

```python
# Test connection
try:
    result = persona.prometheus.query_instant("up")
    print("‚úÖ Prometheus connected")
except Exception as e:
    print(f"‚ùå Prometheus error: {e}")
    print("Check: http://localhost:9090")
```

### Grafana Authentication Issues

```python
# Test Grafana connection
dashboards = persona.grafana.list_dashboards()
if dashboards:
    print(f"‚úÖ Grafana connected - {len(dashboards)} dashboards")
else:
    print("‚ùå Grafana authentication failed")
    print("Check credentials or API key")
```

### No Metrics Available

**Problem**: Queries return no data

**Solutions**:
1. Ensure Prometheus is scraping targets: `http://localhost:9090/targets`
2. Verify Node Exporter is running: `systemctl status node_exporter`
3. Check time ranges - metrics may not exist for requested period
4. Verify PromQL query syntax

## Performance

The persona is designed for minimal overhead:

- **Query latency**: <100ms for instant queries, <1s for range queries
- **Memory footprint**: ~50MB for typical analysis
- **CPU overhead**: <5% during analysis
- **Concurrent queries**: Supports parallel Prometheus queries

## Best Practices

### 1. Start with USE Method

Always begin with a comprehensive USE Method analysis:

```python
# First: Get the big picture
insights = await persona.analyze_use_method()

# Then: Drill down into specific issues
if critical_issues:
    detailed_analysis = await persona.drill_down_analysis(component)
```

### 2. Correlate Multiple Data Sources

Combine Prometheus metrics with Grafana dashboards:

```python
# Prometheus: Raw metrics
use_insights = await persona.analyze_use_method()

# Grafana: Visualized context
dashboard_insights = await persona.analyze_grafana_dashboard(uid)

# Merge insights
all_insights = use_insights + dashboard_insights
```

### 3. Use Time Ranges Wisely

```python
from datetime import datetime, timedelta

# Short-term: Last 5 minutes for immediate issues
start = datetime.now() - timedelta(minutes=5)
end = datetime.now()

# Long-term: Last 24 hours for trends
start = datetime.now() - timedelta(hours=24)
end = datetime.now()
```

### 4. Iterate on Findings

Follow Brendan's methodology:
1. USE Method ‚Üí Identify resource issues
2. Workload Characterization ‚Üí Understand the load
3. Drill-Down ‚Üí Find root cause
4. Latency Analysis ‚Üí Quantify user impact

## References

### Brendan Gregg's Resources

- **Book**: [Systems Performance: Enterprise and the Cloud, 2nd Edition](https://www.brendangregg.com/systems-performance-2nd-edition-book.html)
- **USE Method**: [brendangregg.com/usemethod.html](https://www.brendangregg.com/usemethod.html)
- **Blog**: [brendangregg.com/blog](https://www.brendangregg.com/blog/)
- **Tools**: [github.com/brendangregg](https://github.com/brendangregg)

### Related Documentation

- [CLAUDE.md](../CLAUDE.md) - Project overview and commands
- [CONFIGURATION.md](../CONFIGURATION.md) - Environment setup
- [TROUBLESHOOTING.md](../TROUBLESHOOTING.md) - Common issues

## Contributing

To extend the Brendan Gregg persona:

1. **Add New Methodologies**:
   ```python
   async def _analyze_tsa_method(self) -> List[BrendanGreggInsight]:
       """Implement Thread State Analysis methodology."""
       # Implementation here
   ```

2. **Customize Thresholds**:
   ```python
   # Add environment-specific thresholds
   CUSTOM_THRESHOLDS = {
       "database": {
           "query_time_warning": 100.0,  # ms
           "connection_pool_warning": 80.0,  # %
       }
   }
   ```

3. **Add Prometheus Queries**:
   ```python
   # Add custom queries for specific systems
   CUSTOM_QUERIES = {
       "postgres": {
           "active_connections": "pg_stat_activity_count{state='active'}",
           "slow_queries": "pg_stat_slow_queries_total",
       }
   }
   ```

## License

Part of the system-performance project. See main LICENSE file.

---

**Author**: System Performance Analysis Team
**Based on**: Brendan Gregg's Methodologies
**Version**: 1.0.0
**Last Updated**: 2025-10-28
