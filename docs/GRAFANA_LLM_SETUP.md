# ğŸ¤– IntegraÃ§Ã£o LLM com Grafana - Guia Completo

## âœ… Status: API Server Pronto

**Endpoints LLM disponÃ­veis:**
- ğŸ¨ Dashboard HTML: `http://localhost:8080/dashboard/llm`
- ğŸ” API Insights: `http://localhost:8080/api/insights/llm`

---

## ğŸ“‹ Passo-a-Passo: Adicionar Painel LLM no Grafana

### 1ï¸âƒ£ Acessar o Dashboard do Grafana

1. Abra o Grafana: `http://localhost:3000`
2. Login: `admin` / `admin123`
3. Navegue para o dashboard **"Unified USE Method"** ou qualquer outro que deseja adicionar o painel

### 2ï¸âƒ£ Adicionar Novo Painel

1. Clique em **"Add"** (Ã­cone +) no topo direito
2. Selecione **"Add panel"**
3. Na lista de visualizaÃ§Ãµes, escolha **"Text"**

### 3ï¸âƒ£ Configurar o Painel

**Modo de EdiÃ§Ã£o:**
1. No campo de texto, **altere de "Markdown" para "HTML"** (dropdown no topo)
2. Cole o seguinte cÃ³digo HTML:

```html
<iframe
    src="http://localhost:8080/dashboard/llm"
    width="100%"
    height="800px"
    frameborder="0"
    style="border: none; overflow: hidden;">
</iframe>
```

**ConfiguraÃ§Ãµes do Painel:**
1. **Panel Title:** "ğŸ¤– LLM-Powered Performance Analysis"
2. **Description:** "Intelligent insights generated by MiniMax-M2 (230B parameters)"
3. **Transparent background:** Ativado (opcional)

### 4ï¸âƒ£ Ajustar Tamanho

1. Clique em **"Apply"** para salvar
2. Redimensione o painel arrastando os cantos
3. SugestÃ£o: Largura completa (12 colunas) x Altura 800-1000px

### 5ï¸âƒ£ Salvar Dashboard

1. Clique no Ã­cone de **"Save dashboard"** (ğŸ’¾) no topo
2. Adicione nota: "Added LLM-powered insights panel"
3. Clique em **"Save"**

---

## ğŸ¨ Layout Recomendado

### OpÃ§Ã£o A: Dashboard Separado (Recomendado)
Crie um dashboard exclusivo para anÃ¡lise LLM:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– LLM-Powered Performance Analysis         â”‚
â”‚ (Dashboard dedicado)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Como criar:**
1. Dashboard â†’ New Dashboard
2. Add â†’ Text (HTML mode)
3. Cole o iframe acima
4. Save as "LLM Performance Analysis"

### OpÃ§Ã£o B: Integrado ao USE Method Dashboard
Adicione como Ãºltima seÃ§Ã£o do dashboard existente:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USE Method Metrics (Prometheus)             â”‚
â”‚ â”œâ”€ CPU Utilization                          â”‚
â”‚ â”œâ”€ Memory Usage                             â”‚
â”‚ â””â”€ Network/Disk                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š Rule-Based Insights                      â”‚
â”‚ (http://localhost:8080/dashboard)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¤– LLM-Powered Insights â­ NOVO!            â”‚
â”‚ (http://localhost:8080/dashboard/llm)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Troubleshooting

### Problema: "Refused to display in a frame"
**SoluÃ§Ã£o:** JÃ¡ configurado! O `GF_PANELS_DISABLE_SANITIZE_HTML=true` estÃ¡ no docker-compose.yml

Verifique se estÃ¡ ativo:
```bash
docker exec grafana env | grep SANITIZE
# Deve retornar: GF_PANELS_DISABLE_SANITIZE_HTML=true
```

### Problema: Dashboard vazio ou "Loading..."
**PossÃ­veis causas:**
1. **Ollama nÃ£o estÃ¡ rodando:**
   ```bash
   curl http://localhost:11434/api/tags
   ```

2. **Modelo MiniMax-M2 nÃ£o instalado:**
   ```bash
   ollama list | grep minimax
   ```

3. **API server nÃ£o estÃ¡ rodando:**
   ```bash
   curl http://localhost:8080/health
   ```

4. **Prometheus inacessÃ­vel:**
   ```bash
   curl http://177.93.132.48:9090/api/v1/query?query=up
   ```

### Problema: "Error: LLM analysis failed"
**Ver logs:**
```bash
tail -f /tmp/brendan_api.log
```

**SoluÃ§Ãµes:**
- Verificar se Ollama estÃ¡ rodando: `ollama list`
- Verificar mÃ©tricas Prometheus: `curl http://177.93.132.48:9090/api/v1/query?query=node_load1`
- Reiniciar API server: `pkill -f brendan_api_server && uv run python src/brendan_api_server.py &`

---

## ğŸš€ Testando Antes de Adicionar ao Grafana

### Teste 1: Abrir no Navegador
```
http://localhost:8080/dashboard/llm
```

**Esperado:**
- Header roxo com "ğŸ¤– LLM-Powered Performance Analysis"
- Spinner de loading por 30-60 segundos
- Insights renderizados com cards coloridos

### Teste 2: Verificar API JSON
```bash
curl http://localhost:8080/api/insights/llm | jq
```

**Esperado:**
```json
{
  "source": "llm",
  "model": "minimax-m2:cloud",
  "total": 5,
  "insights": [...]
}
```

### Teste 3: Verificar Tempo de Resposta
```bash
time curl -s http://localhost:8080/api/insights/llm > /dev/null
```

**Esperado:** ~30-60 segundos

---

## ğŸ“Š ComparaÃ§Ã£o: Rule-Based vs LLM

### Dashboard Rule-Based (`/dashboard`)
- âš¡ RÃ¡pido: < 1 segundo
- ğŸ“Š Dados diretos de validation reports
- ğŸ¯ Insights bÃ¡sicos baseados em thresholds

### Dashboard LLM (`/dashboard/llm`) â­
- ğŸ¤– Inteligente: AnÃ¡lise com LLM 230B parÃ¢metros
- â±ï¸ Mais lento: 30-60 segundos
- ğŸ’¡ Insights contextuais e profundos
- ğŸ“– Linguagem natural fluente
- ğŸ”— Relaciona mÃºltiplas mÃ©tricas

**RecomendaÃ§Ã£o:** Use ambos!
- Rule-based para monitoramento contÃ­nuo
- LLM para investigaÃ§Ã£o profunda de problemas

---

## ğŸ¯ Exemplo de VisualizaÃ§Ã£o

Quando o painel LLM carregar, vocÃª verÃ¡:

### Header
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– LLM-Powered Performance Analysis      â”‚
â”‚ Intelligent insights by MiniMax-M2       â”‚
â”‚ (230B parameters)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stats Cards
```
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚  5   â”‚  1   â”‚  2   â”‚  âœ“   â”‚
â”‚Total â”‚Crit  â”‚High  â”‚Statusâ”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

### Insight Card Exemplo
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ CPU Near Saturation                  HIGH â•‘
â•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢
â•‘ ğŸ“Š Observation                            â•‘
â•‘ CPU utilization is at 88.72% with load   â•‘
â•‘ average of 21.09 on 8-core system...     â•‘
â•‘                                           â•‘
â•‘ ğŸ¯ Root Cause                             â•‘
â•‘ The load per CPU of 2.64 means           â•‘
â•‘ approximately 2.64 processes competing... â•‘
â•‘                                           â•‘
â•‘ âš¡ Immediate Action                       â•‘
â•‘ Run `top` to identify the top CPU        â•‘
â•‘ consuming processes...                    â•‘
â•‘                                           â•‘
â•‘ ğŸ” Investigation Steps                    â•‘
â•‘ 1. Run mpstat -P ALL 1                   â•‘
â•‘ 2. Check with perf top                   â•‘
â•‘ 3. Review application logs               â•‘
â•‘                                           â•‘
â•‘ ğŸ’¡ Long-term Fix                          â•‘
â•‘ Optimize hot code paths or scale         â•‘
â•‘ horizontally...                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ”„ Auto-Refresh

O dashboard LLM tem **auto-refresh de 5 minutos**:
- Primeira anÃ¡lise: Ao carregar a pÃ¡gina
- PrÃ³ximas: A cada 5 minutos automaticamente
- Motivo: LLM analysis leva 30-60s, nÃ£o faz sentido refresh muito frequente

Se quiser alterar:
```javascript
// Linha 742-743 em src/brendan_api_server.py
setInterval(loadLLMInsights, 300000);  // 5 min (padrÃ£o)
// Altere para:
setInterval(loadLLMInsights, 180000);  // 3 min
setInterval(loadLLMInsights, 600000);  // 10 min
```

---

## ğŸ’¡ Dicas Pro

### 1. Dashboard Combinado
Crie um dashboard com 3 painÃ©is:
1. **MÃ©tricas USE Method** (Prometheus)
2. **Insights Rule-Based** (iframe para `/dashboard`)
3. **Insights LLM** (iframe para `/dashboard/llm`)

### 2. Refresh Inteligente
Configure refresh do Grafana para **5 minutos** no dashboard LLM:
- Clique em âš™ï¸ (Dashboard settings)
- Auto Refresh â†’ Adicione "5m"

### 3. VariÃ¡veis Grafana
Adicione variÃ¡vel para alternar entre anÃ¡lises:
```
analysis_type: rule-based | llm
URL: http://localhost:8080/dashboard/${analysis_type}
```

### 4. Alertas
Configure alertas para quando LLM detectar CRITICAL:
- Use Grafana Alerting com JSON API data source
- Query: `http://localhost:8080/api/insights/llm`
- CondiÃ§Ã£o: `total_critical > 0`

---

## ğŸ“ Arquivos Relacionados

- **API Server:** `src/brendan_api_server.py`
- **LLM Agent:** `src/brendan_llm_agent.py`
- **Docker Compose:** `docker-compose.yml`
- **Tests:** `examples/test_brendan_llm.py`

---

## âœ… Checklist Final

Antes de usar no Grafana, verifique:

- [ ] Ollama rodando: `curl http://localhost:11434/api/tags`
- [ ] Modelo instalado: `ollama list | grep minimax`
- [ ] API server rodando: `curl http://localhost:8080/health`
- [ ] Prometheus acessÃ­vel: `curl http://177.93.132.48:9090/api/v1/query?query=up`
- [ ] Dashboard carrega: Abrir `http://localhost:8080/dashboard/llm` no browser
- [ ] Grafana permite HTML: `docker exec grafana env | grep SANITIZE`

---

**Pronto para adicionar no Grafana!** ğŸ‰

Siga o passo-a-passo acima e vocÃª terÃ¡ anÃ¡lise LLM integrada ao seu dashboard de performance.
